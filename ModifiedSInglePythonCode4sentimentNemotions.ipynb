{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5376492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and saving RoBERTa model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873779ecb68f49559254dcb0403709f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/356 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e647993f076b4b258b1f5abb5db8c2f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Victor\\.cache\\huggingface\\hub\\models--arpanghoshal--EmoRoBERTa. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Victor\\AppData\\Roaming\\Python\\Python39\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01093cb524ef4adaa813798e606dcfe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Victor\\AppData\\Roaming\\Python\\Python39\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at arpanghoshal/EmoRoBERTa.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc46833a909d415d8bd6df78a839a449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05f9efb674a4a8289f1b63d8987da31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875cfab94d1442ada7180d365f34219f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9deb05c4d76472eaca8f78fb278b6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed and results saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import subprocess\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Define paths for the saved model\n",
    "MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "MODEL_PATH = \"saved_roberta_model.pth\"\n",
    "\n",
    "# Check if the model has already been saved locally\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(\"Loading saved RoBERTa model...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = torch.load(MODEL_PATH)  # Load the saved model\n",
    "else:\n",
    "    print(\"Downloading and saving RoBERTa model...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "    torch.save(model, MODEL_PATH)  # Save the model locally for future use\n",
    "\n",
    "def polarity_scores_roberta(ex):\n",
    "    encoded_text = tokenizer(ex, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "        \n",
    "    scores_dict = {'roberta_neg': scores[0],\n",
    "                   'roberta_neu': scores[1],\n",
    "                   'roberta_pos': scores[2],\n",
    "                   'roberta_polarity': 1 if scores[2] > scores[0] else 0\n",
    "                  }\n",
    "    return scores_dict\n",
    "\n",
    "# Load and process data\n",
    "df = pd.read_csv('Breakfast Cooking - Kids Game - Copy - Copy.csv', encoding='utf-8')\n",
    "\n",
    "# Run the polarity scores on the dataFrame\n",
    "res = {}\n",
    "robertaArr = {}\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        text = row['Content']\n",
    "        myId = row['Id']\n",
    "        roberta_result = polarity_scores_roberta(text)\n",
    "        robertaArr[myId] = roberta_result\n",
    "        both = {**roberta_result}\n",
    "        res[myId] = both\n",
    "    except RuntimeError:\n",
    "        print(f'Broke for {myId}')\n",
    "        \n",
    "roberta = pd.DataFrame(robertaArr).T\n",
    "roberta = roberta.reset_index().rename(columns={'index': 'Id'})\n",
    "roberta = roberta.merge(df, how='left')\n",
    "\n",
    "# Emotion analysis pipeline using EmoRoBERTa\n",
    "emotion_pipeline = pipeline('sentiment-analysis', model='arpanghoshal/EmoRoBERTa')\n",
    "\n",
    "def get_emotional_label(text):\n",
    "    return (emotion_pipeline(text)[0]['label'])\n",
    "\n",
    "roberta['emotion'] = roberta['Content'].apply(get_emotional_label)\n",
    "\n",
    "# Save the DataFrame with emotion labels to CSV\n",
    "csv_file = \"BreakFastCooking_emotionNew.csv\"\n",
    "roberta.to_csv(csv_file, index=False)\n",
    "\n",
    "print(\"Process completed and results saved to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867319a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
